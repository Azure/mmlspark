{
    "cells": [{
        "cell_type": "markdown",
        "source": ["### News Recommendation ALS Example Databricks Notebook\n##### by Daniel Ciborowski, dciborow@microsoft.com\n\n##### Copyright (c) Microsoft Corporation. All rights reserved.\n\n##### Licensed under the MIT License.\n\n##### Setup\n1. Create new Cluster, DB 4.1, Spark 2.3.0, Python3\n1. (Optional for Ranking Metrics) From Maven add to cluster the following jar: Azure:mmlspark:0.15"],
        "metadata": {}
    }, {
        "cell_type": "code",
        "source": ["import pandas as pd\nimport random\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import col, collect_list"],
        "metadata": {},
        "outputs": [],
        "execution_count": 2
    }, {
        "cell_type": "code",
        "source": ["raw = [\n  {'userId': 1, 'itemId': 1, 'rating':  random.randint(0, 10)},\n  {'userId': 2, 'itemId': 1, 'rating':  random.randint(0, 10)},\n  {'userId': 3, 'itemId': 1, 'rating':  random.randint(0, 10)},\n  {'userId': 4, 'itemId': 1, 'rating':  random.randint(0, 10)},\n  {'userId': 5, 'itemId': 1, 'rating':  random.randint(0, 10)},\n  {'userId': 1, 'itemId': 2, 'rating':  random.randint(0, 10)},\n  {'userId': 2, 'itemId': 2, 'rating':  random.randint(0, 10)},\n  {'userId': 3, 'itemId': 2, 'rating':  random.randint(0, 10)},\n  {'userId': 4, 'itemId': 2, 'rating':  random.randint(0, 10)},\n  {'userId': 5, 'itemId': 2, 'rating':  random.randint(0, 10)},\n  {'userId': 1, 'itemId': 3, 'rating':  random.randint(0, 10)},\n  {'userId': 2, 'itemId': 3, 'rating':  random.randint(0, 10)},\n  {'userId': 3, 'itemId': 3, 'rating':  random.randint(0, 10)},\n  {'userId': 4, 'itemId': 3, 'rating':  random.randint(0, 10)},\n  {'userId': 5, 'itemId': 3, 'rating':  random.randint(0, 10)},\n  {'userId': 1, 'itemId': 4, 'rating':  random.randint(0, 10)},\n  {'userId': 2, 'itemId': 4, 'rating':  random.randint(0, 10)},\n  {'userId': 3, 'itemId': 4, 'rating':  random.randint(0, 10)},\n  {'userId': 4, 'itemId': 4, 'rating':  random.randint(0, 10)},\n  {'userId': 5, 'itemId': 4, 'rating':  random.randint(0, 10)},  \n  {'userId': 1, 'itemId': 5, 'rating':  random.randint(0, 10)},\n  {'userId': 2, 'itemId': 5, 'rating':  random.randint(0, 10)},\n  {'userId': 3, 'itemId': 5, 'rating':  random.randint(0, 10)},\n  {'userId': 4, 'itemId': 5, 'rating':  random.randint(0, 10)},\n  {'userId': 5, 'itemId': 5, 'rating':  random.randint(0, 10)},   \n]\n\nday1 = pd.DataFrame(raw)\nday2=pd.DataFrame(raw)\nday2['itemId'] = day2['itemId']+10\nday3=pd.DataFrame(raw)\nday3['itemId'] = day3['itemId']+20\nday4=pd.DataFrame(raw)\nday4['itemId'] = day4['itemId']+30\n\ndata = day1 \\\n  .append(day2) \\\n  .append(day3) \\\n  .append(day4) \\\n  .sample(frac=0.75, replace=False)\n\nspark = SparkSession.builder.getOrCreate()\nratings = spark.createDataFrame(data)\ndisplay(ratings.select('userId','itemId','rating').orderBy('userId','itemId'))"],
        "metadata": {},
        "outputs": [],
        "execution_count": 3
    }, {
        "cell_type": "code",
        "source": ["# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\nalgo = ALS(userCol=\"userId\", itemCol=\"itemId\", implicitPrefs=True, coldStartStrategy=\"drop\")\nmodel = algo.fit(ratings)"],
        "metadata": {},
        "outputs": [],
        "execution_count": 4
    }, {
        "cell_type": "code",
        "source": ["predictions = model.transform(ratings)\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))"],
        "metadata": {},
        "outputs": [],
        "execution_count": 5
    }, {
        "cell_type": "code",
        "source": ["from mmlspark.RankingAdapter import RankingAdapter\nfrom mmlspark.RankingEvaluator import RankingEvaluator\n\noutput = RankingAdapter(mode='allUsers', k=5, recommender=algo) \\\n  .fit(ratings) \\\n  .transform(ratings)\n\nmetrics = ['ndcgAt','map','recallAtK','mrr','fcp']\nmetrics_dict = {}\nfor metric in metrics:\n    metrics_dict[metric] = RankingEvaluator(k=3, metricName=metric).evaluate(output)\n    \nmetrics_dict    "],
        "metadata": {},
        "outputs": [],
        "execution_count": 6
    }, {
        "cell_type": "code",
        "source": ["def recommendSubset(self, df):\n  def Func(lines):\n    out = []\n    for i in range(len(lines[1])):\n      out += [(lines[1][i],lines[2][i])]\n    return lines[0], out\n\n  tup = StructType([\n    StructField('itemId', IntegerType(), True),\n    StructField('rating', FloatType(), True)\n  ])\n  array_type = ArrayType(tup, True)\n\n  scoring = spark.createDataFrame(day4)\n  scored = self.transform(scoring)\n\n  recs = scored \\\n    .groupBy(col('userId')) \\\n    .agg(collect_list(col(\"itemId\")),collect_list(col(\"prediction\"))) \\\n    .rdd \\\n    .map(Func) \\\n    .toDF() \\\n    .withColumnRenamed(\"_1\",\"userId\") \\\n    .withColumnRenamed(\"_2\",\"recommendations\") \\\n    .select(col(\"userId\"),col(\"recommendations\").cast(array_type))\n\n  return recs\n\nimport pyspark\npyspark.ml.recommendation.ALSModel.recommendSubset = recommendSubset"],
        "metadata": {},
        "outputs": [],
        "execution_count": 7
    }, {
        "cell_type": "code",
        "source": ["day4df = spark.createDataFrame(day4)\nrecs = model.recommendSubset(day4df)\n\ndisplay(recs.orderBy('userId'))"],
        "metadata": {},
        "outputs": [],
        "execution_count": 8
    }, {
        "cell_type": "code",
        "source": [""],
        "metadata": {},
        "outputs": [],
        "execution_count": 9
    }],
    "metadata": {
        "anaconda-cloud": {},
        "kernelspec": {
            "display_name": "Python [default]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
