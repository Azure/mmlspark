<?xml version="1.0" ?>
<testsuite errors="1" failures="0" name="TrainValidRecommendSplitSpec-20180118081413" tests="2" time="57.666">
	<testcase classname="TrainValidRecommendSplitSpec" name="test_all_tiny" time="28.782"/>
	<testcase classname="TrainValidRecommendSplitSpec" name="test_all_large" time="28.884">
		<error message="'Field &quot;rating&quot; does not exist.'" type="IllegalArgumentException">
<![CDATA[Traceback (most recent call last):
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/home/dciborow/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py", line 319, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling o270.fit.
: java.lang.IllegalArgumentException: Field "rating" does not exist.
	at org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:266)
	at org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:266)
	at scala.collection.MapLike$class.getOrElse(MapLike.scala:128)
	at scala.collection.AbstractMap.getOrElse(Map.scala:59)
	at org.apache.spark.sql.types.StructType.apply(StructType.scala:265)
	at org.apache.spark.ml.util.SchemaUtils$.checkNumericType(SchemaUtils.scala:71)
	at org.apache.spark.ml.recommendation.ALSParams$class.validateAndTransformSchema(ALS.scala:254)
	at org.apache.spark.ml.recommendation.ALS.validateAndTransformSchema(ALS.scala:516)
	at org.apache.spark.ml.recommendation.ALS.transformSchema(ALS.scala:638)
	at org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:606)
	at com.microsoft.ml.spark.MsftRecommendation.fit(MsftRecommendation.scala:106)
	at com.microsoft.ml.spark.MsftRecommendation.fit(MsftRecommendation.scala:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dciborow/mmlspark2/src/msft-recommendation/src/test/python/TrainValidRecommendSplitSpec.py", line 157, in test_all_large
    tvmodel = tvRecommendationSplit.fit(transformedDf)
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py", line 64, in fit
    return self._fit(dataset)
  File "/home/dciborow/lib/conda/lib/python3.6/site-packages/mmlspark/TrainValidRecommendSplit.py", line 599, in _fit
    models = est.fit(train, epm)
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py", line 59, in fit
    return [self.fit(dataset, paramMap) for paramMap in params]
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py", line 59, in <listcomp>
    return [self.fit(dataset, paramMap) for paramMap in params]
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py", line 62, in fit
    return self.copy(params)._fit(dataset)
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py", line 265, in _fit
    java_model = self._fit_java(dataset)
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py", line 262, in _fit_java
    return self._java_obj.fit(dataset._jdf)
  File "/home/dciborow/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py", line 1133, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 79, in deco
    raise IllegalArgumentException(s.split(': ', 1)[1], stackTrace)
pyspark.sql.utils.IllegalArgumentException: 'Field "rating" does not exist.'
]]>		</error>
	</testcase>
	<system-out>
<![CDATA[[Row(customerID=12, recommendations=[Row(itemID=1, rating=4.902277946472168), Row(itemID=10, rating=4.886264801025391), Row(itemID=19, rating=4.272840976715088)])]
[Row(customerID=12, recommendations=[Row(itemID=32, rating=3.9464850425720215), Row(itemID=19, rating=3.820230722427368), Row(itemID=10, rating=3.5927631855010986)])]
[0.389141307100932]
ListBuffer(Map(map -> 0.34259259259259256, mapk -> 0.2222222222222222, maxDiversity -> 1.75, diversityAtK -> 0.875, recallAtK -> 0.2222222222222222, ndcgAt -> 0.389141307100932))
]]>	</system-out>
	<system-err>
<![CDATA[Exception ignored in: <bound method JavaParams.__del__ of TrainValidRecommendSplitModel_4a9093b6974e144c3067>
Traceback (most recent call last):
  File "/home/dciborow/lib/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py", line 105, in __del__
  File "/home/dciborow/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py", line 1870, in detach
AttributeError: 'NoneType' object has no attribute '_detach'
]]>	</system-err>
</testsuite>
